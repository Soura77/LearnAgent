{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8939b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain langchain_openai langchain_core langgraph langfuse dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e730e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import setup_langfuse_tracer\n",
    "from my_config import MyConfig\n",
    "\n",
    "my_config = MyConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bb24d",
   "metadata": {},
   "source": [
    "## Langfuse Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328f3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse = Langfuse(\n",
    "    public_key = my_config.LANGFUSE_PUBLIC_KEY,\n",
    "    secret_key = my_config.LANGFUSE_SECRET_KEY,\n",
    "    host = my_config.LANGFUSE_HOST\n",
    ")\n",
    "langfuse_handler1 = CallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39a713",
   "metadata": {},
   "source": [
    "## OpenAI Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Please setp your own key.\n",
    "# os.environ[\"OPENAI_API_KEY\"] = my_config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94605e",
   "metadata": {},
   "source": [
    "## Get the LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6dd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", streaming=True)\n",
    "#.achat, .achatstream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5fcbe",
   "metadata": {},
   "source": [
    "## Define the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d289dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def extract_text(img_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from an image file using a multimodal model.\n",
    "\n",
    "    Args:\n",
    "        img_path: A local image file path (strings).\n",
    "\n",
    "    Returns:\n",
    "        A single string containing the concatenated text extracted from each image.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    try:\n",
    "\n",
    "        # Read image and encode as base64\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "\n",
    "        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "        # Prepare the prompt including the base64 image data\n",
    "        message = [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"Extract all the text from this image. \"\n",
    "                            \"Return only the extracted text, no explanations.\"\n",
    "                        ),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_base64}\"\n",
    "                        },\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Call the vision-capable model\n",
    "        response = vision_llm.invoke(message, config={\"langfuse_handler\": langfuse_handler})\n",
    "\n",
    "        # Append extracted text\n",
    "        all_text += response.content + \"\\n\\n\"\n",
    "\n",
    "        return all_text.strip()\n",
    "    except Exception as e:\n",
    "        # You can choose whether to raise or just return an empty string / error message\n",
    "        error_msg = f\"Error extracting text: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "def sum(a: int, b: int) -> float:\n",
    "    \"\"\"Sum a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> float:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def substract(a: int, b: int) -> float:\n",
    "    \"\"\"Substract a and b.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def get_biggest_united_supporter() -> str:\n",
    "    \"\"\"Looks at the all manchester united fanbase and returns the biggest mannchester united supporter in the world\"\"\"\n",
    "    return \"Souradeep  is the biggest Manchester United supporter in the world. He is a die-hard fan of the club and has been supporting them for almost 29 years.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d609755",
   "metadata": {},
   "source": [
    "## Bind tools to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d4fe9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    divide,\n",
    "    sum,\n",
    "    get_biggest_united_supporter\n",
    "    #multiply,\n",
    "    #substract,\n",
    "    #extract_text\n",
    "]\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d047",
   "metadata": {},
   "source": [
    "## Defining Agent's State\n",
    "This state is a little more complex than the previous ones we have seen. AnyMessage is a class from Langchain that defines messages, and add_messages is an operator that adds the latest message rather than overwriting it with the latest state.\n",
    "\n",
    "This is a new concept in LangGraph, where you can add operators in your state to define the way they should interact together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bc170de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The document provided\n",
    "    input_file: Optional[str]  # Contains file path (PDF/PNG)\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542ff84",
   "metadata": {},
   "source": [
    "## The nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f760376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    # System message\n",
    "    textual_description_of_tool=\"\"\"\n",
    "extract_text(img_path: str) -> str:\n",
    "    Extract text from an image file using a multimodal model.\n",
    "\n",
    "    Args:\n",
    "        img_path: A local image file path (strings).\n",
    "\n",
    "    Returns:\n",
    "        A single string containing the concatenated text extracted from each image.\n",
    "\n",
    "divide(a: int, b: int) -> float:\n",
    "    Divide a and b\n",
    "    Args:\n",
    "        a: The numerator (int).\n",
    "        b: The denominator (int).\n",
    "    Returns:\n",
    "        The result of the division (float).\n",
    "\"\"\"\n",
    "    image=state[\"input_file\"]\n",
    "    sys_msg = SystemMessage(content=f\"You are a helpful butler named Alfred that serves Mr. Wayne and Batman. You can analyse documents and run computations with provided tools:\\n{textual_description_of_tool} \\n You have access to some optional images. Currently the loaded image is: {image}\")\n",
    "\n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"input_file\": state[\"input_file\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce9aa9",
   "metadata": {},
   "source": [
    "## The ReAct Pattern: How I Assist Mr. Wayne\n",
    "Allow me to explain the approach in this agent. The agent follows what’s known as the ReAct pattern (Reason-Act-Observe)\n",
    "\n",
    "1. **Reason** about his documents and requests\n",
    "2. **Act** by using appropriate tools\n",
    "3. **Observe** the results\n",
    "4. **Repeat** as necessary until I’ve fully addressed his needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52c132dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show the butler's thought process\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714b8af",
   "metadata": {},
   "source": [
    "We define a tools node with our list of tools. The assistant node is just our model with bound tools. We create a graph with assistant and tools nodes.\n",
    "\n",
    "We add a tools_condition edge, which routes to End or to tools based on whether the assistant calls a tool.\n",
    "\n",
    "Now, we add one new step:\n",
    "\n",
    "We connect the tools node back to the assistant, forming a loop.\n",
    "\n",
    "- After the assistant node executes, tools_condition checks if the model’s output is a tool call.\n",
    "- If it is a tool call, the flow is directed to the tools node.\n",
    "- The tools node connects back to assistant.\n",
    "- This loop continues as long as the model decides to call tools.\n",
    "- If the model response is not a tool call, the flow is directed to END, terminating the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7c3b8",
   "metadata": {},
   "source": [
    "## The Butler in Action\n",
    "### Example 1: Simple Calculations\n",
    "\n",
    "Here is an example to show a simple use case of an agent using a tool in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b90f6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is biggest man utd fan.Need the name of the person and snumber of years suppoerted ina tablular form only\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_biggest_united_supporter (call_GpDWsWei9BspFYJxQajBHnjW)\n",
      " Call ID: call_GpDWsWei9BspFYJxQajBHnjW\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_biggest_united_supporter\n",
      "\n",
      "Souradeep  is the biggest Manchester United supporter in the world. He is a die-hard fan of the club and has been supporting them for almost 29 years.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "| Name      | Years Supported |\n",
      "|-----------|-----------------|\n",
      "| Souradeep | 29              |\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Who is biggest man utd fan.Need the name of the person and snumber of years suppoerted ina tablular form only\")]\n",
    "messages = react_graph.invoke(\n",
    "    {\n",
    "        \"messages\": messages\n",
    "        , \"input_file\": None\n",
    "    }\n",
    "    , config={\"callbacks\": [langfuse_handler1]}\n",
    ")\n",
    "# Show the messages\n",
    "for m in messages['messages']:\n",
    "    #m.pretty_print()\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426bf9a",
   "metadata": {},
   "source": [
    "## Stream Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89d1efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_biggest_united_supporter (call_lqDaVH74aSfay9glQu9RjGpY)\n",
      " Call ID: call_lqDaVH74aSfay9glQu9RjGpY\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_biggest_united_supporter\n",
      "\n",
      "Souradeep  is the biggest Manchester United supporter in the world. He is a die-hard fan of the club and has been supporting them for almost 29 years.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "| Name     | Years Supported |\n",
      "|----------|-----------------|\n",
      "| Souradeep| 29              |\n"
     ]
    }
   ],
   "source": [
    "#messages = [HumanMessage(content=\"Who is biggest man utd fan.Need the name of the person and snumber of years suppoerted ina tablular form only\")]\n",
    "messages = [{'role': 'user', 'content': 'Who is biggest man utd fan.Need the name of the person and snumber of years suppoerted ina tablular form only'}]\n",
    "input = { \"messages\": messages\n",
    "        , \"input_file\": None}\n",
    "# Stream the response\n",
    "for m in react_graph.stream( input= input, config={\"callbacks\": [langfuse_handler1]}):\n",
    "    for key,value in m.items():\n",
    "        #print(value['messages'][0])\n",
    "        value['messages'][0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d71dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is biggest man utd fan.Need the name of the person and snumber of years suppoerted ina tablular form only\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_biggest_united_supporter (call_4xUXzeonZkRiEr7FzECqRH5Z)\n",
      " Call ID: call_4xUXzeonZkRiEr7FzECqRH5Z\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_biggest_united_supporter\n",
      "\n",
      "Souradeep  is the biggest Manchester United supporter in the world. He is a die-hard fan of the club and has been supporting them for almost 29 years.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "| Name     | Years Supported |\n",
      "|----------|-----------------|\n",
      "| Souradeep| 29              |\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how many years has he supported\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Souradeep has supported Manchester United for 29 years.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "messages = react_graph.invoke({\n",
    "        \"messages\": reduce(\n",
    "            lambda left, right: add_messages(left, right)\n",
    "            , messages['messages']\n",
    "                + [HumanMessage(content=\"how many years has he supported\")])\n",
    "        , \"input_file\": None\n",
    "    }, config={\"callbacks\": [langfuse_handler1]})\n",
    "\n",
    "# Show the messages\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8dc643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.tool.ToolMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "Souradeep has supported Manchester United for 29 years.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    #m.pretty_print()\n",
    "    print(type(m))\n",
    "\n",
    "print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05559cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assign evaluated value of given solution to variable A: 2*3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The evaluated value of the given expression \\(2 \\times 3\\) is 6. Therefore, variable A is assigned the value 6.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Assign evaluated value of given solution to variable A: 2*3\")]\n",
    "messages = react_graph.invoke(\n",
    "    {\n",
    "        \"messages\": messages\n",
    "        , \"input_file\": None\n",
    "    }\n",
    "    , config={\"callbacks\": [langfuse_handler1]}\n",
    ")\n",
    "# Show the messages\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19cb3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "messages = react_graph.invoke({\n",
    "        \"messages\": reduce(\n",
    "            lambda left, right: add_messages(left, right)\n",
    "            , messages['messages']\n",
    "                + [HumanMessage(content=\"Assign evaluated value of given solution to variable B: 1*2\")])\n",
    "        , \"input_file\": None\n",
    "    }, config={\"callbacks\": [langfuse_handler1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aa00c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assign evaluated value of given solution to variable A: 2*3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The evaluated value of the given expression \\(2 \\times 3\\) is 6. Therefore, variable A is assigned the value 6.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assign evaluated value of given solution to variable B: 1*2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The evaluated value of the given expression \\(1 \\times 2\\) is 2. Therefore, variable B is assigned the value 2.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is A + B\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The value of A is 6 and the value of B is 2. Hence, \\(A + B = 6 + 2 = 8\\).\n"
     ]
    }
   ],
   "source": [
    "messages = react_graph.invoke({\n",
    "        \"messages\": reduce(\n",
    "            lambda left, right: add_messages(left, right)\n",
    "            , messages['messages']\n",
    "                + [HumanMessage(content=\"What is A + B\")])\n",
    "        , \"input_file\": None\n",
    "    })\n",
    "\n",
    "# Show the messages\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7a2d3",
   "metadata": {},
   "source": [
    "### Example 2: Analyzing Master Wayne’s Training Documents\n",
    "When Master Wayne leaves his training and meal notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f34eb12b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langfuse_handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# with open(\"data/Batman_training_and_meals.png\", \"rb\") as img_file:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#     img_base64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#     , config={\"callbacks\": [langfuse_handler]}\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     28\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mAccording to the note provided by Mr. Wayne in the provided images. What\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the list of items I should buy for the dinner menu?\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m     29\u001b[39m response = react_graph.invoke(\n\u001b[32m     30\u001b[39m     {\n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages\n\u001b[32m     32\u001b[39m         , \u001b[33m\"\u001b[39m\u001b[33minput_file\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdata/Batman_training_and_meals.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     , config={\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mlangfuse_handler\u001b[49m]}\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Show the messages\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[31mNameError\u001b[39m: name 'langfuse_handler' is not defined"
     ]
    }
   ],
   "source": [
    "# with open(\"data/Batman_training_and_meals.png\", \"rb\") as img_file:\n",
    "#     img_base64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# messages = [HumanMessage(\n",
    "#     content=[\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"text\": (\n",
    "#                 \"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\"\n",
    "#             ),\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"image_url\",\n",
    "#             \"image_url\": {\n",
    "#                 \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "#             },\n",
    "#         },\n",
    "#     ]\n",
    "# )]\n",
    "# messages = react_graph.invoke(\n",
    "#     {\n",
    "#         \"messages\": messages\n",
    "#         , \"input_file\": None\n",
    "#     }\n",
    "#     , config={\"callbacks\": [langfuse_handler]}\n",
    "# )\n",
    "\n",
    "messages = [HumanMessage(content=\"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\")]\n",
    "response = react_graph.invoke(\n",
    "    {\n",
    "        \"messages\": messages\n",
    "        , \"input_file\": \"data/Batman_training_and_meals.png\"\n",
    "    }\n",
    "    , config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "# Show the messages\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9386378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
